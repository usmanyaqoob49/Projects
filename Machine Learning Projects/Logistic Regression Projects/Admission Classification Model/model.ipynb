{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* We have historical data from previous applicants that you can use as a training set for logistic regression. \n",
    "* For each training example, We have the applicant’s scores on two exams and the admissions decision. \n",
    "* Our task is to build a classification model that estimates an applicant’s probability of admission based on the scores from those two exams. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = np.loadtxt('datasets/ex2data1.txt', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first two columns have the subjects marks that we are including\n",
    "x_train = data[:,:2]\n",
    "\n",
    "#result training data i.e all the rows of second columns have 0 and 1 means \n",
    "#admitted or not admitted\n",
    "y_train = data[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements in X_train are:\n",
      " [[34.62365962 78.02469282]\n",
      " [30.28671077 43.89499752]\n",
      " [35.84740877 72.90219803]\n",
      " [60.18259939 86.3085521 ]\n",
      " [79.03273605 75.34437644]]\n",
      "Type of x_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements in X_train are:\\n\", x_train[:5])\n",
    "print(\"Type of x_train:\",type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements in y_train are:\n",
      " [0. 0. 0. 1. 1.]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements in y_train are:\\n\", y_train[:5])\n",
    "print(\"Type of y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is: (100, 2)\n",
      "The shape of y_train is: (100,)\n",
      "We have m = 100 training examples\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of x_train is: ' + str(x_train.shape))\n",
    "print ('The shape of y_train is: ' + str(y_train.shape))\n",
    "print ('We have m = %d training examples' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e6beae8e08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive = y_train == 1\n",
    "negative = y_train == 0\n",
    "\n",
    "            #positive of column 0  and  column 1\n",
    "\n",
    "#means for y ==1, subjext 1 (column 0) will be x plotted against subject 2 (column 1)\n",
    "plt.plot(x_train[positive, 0], x_train[positive, 1],'k+', label = 'Admitted')\n",
    "\n",
    "#so fot y == 0, simply plot all points in x and y plane\n",
    "plt.plot(x_train[negative, 0], x_train[negative, 1],'yo',  label = 'Not Admitted')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Score of Exam 1\")\n",
    "plt.ylabel(\"Score of Exam 2\")\n",
    "plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a logistic regression model to fit this data.\n",
    "- With this model, you can then predict if a new student will be admitted based on their scores on the two exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sigmoid function\n",
    "We need sigmoid function so that we can make a classification model for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):       \n",
    "    g = 1 / (1 + np.exp(-z))    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know from graph of logistic regression:\n",
    "- For large positive values of x, the sigmoid should be close to 1, while for large negative values, the sigmoid should be close to 0. \n",
    "- Evaluating `sigmoid(0)` should give you exactly 0.5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n"
     ]
    }
   ],
   "source": [
    "#checling sigmoid function\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost function for logistic regression\n",
    "\n",
    "\n",
    "As logistic regression's cost function is of the form \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "where\n",
    "* m is the number of training examples in the dataset\n",
    "\n",
    "\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is - \n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$, which is the actual label\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b)$ where function $g$ is the sigmoid function.\n",
    "    * It might be helpful to first calculate an intermediate variable $z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b = w_0x^{(i)}_0 + ... + w_{n-1}x^{(i)}_{n-1} + b$ where $n$ is the number of features, before calculating $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x, y, w, b, lambda_ = 1):\n",
    "    m, n = x.shape\n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        z_wb_i = np.dot(w, x[i]) + b\n",
    "        f_wb_i = sigmoid(z_wb_i)\n",
    "        cost += (-y[i] * np.log(f_wb_i)) - (1 - y[i]) * np.log(1 - f_wb_i)\n",
    "        \n",
    "    total_cost = cost / m\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost value with these values of w and b:  0.6931471805599458\n"
     ]
    }
   ],
   "source": [
    "#checking cost function\n",
    "m, n = x_train.shape\n",
    "\n",
    "w_temp = np.zeros(n)\n",
    "b_temp = 0.\n",
    "\n",
    "print(\"cost value with these values of w and b: \", compute_cost(x_train, y_train, w_temp, b_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient for logistic regression\n",
    "Gradient descent algorithm is:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "where, parameters $b$, $w_j$ are all updated simultaniously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For dj/dw and dj/db Values:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, w, b, lambda_ = None):\n",
    "    m, n = x.shape\n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        z_i = np.dot(x[i],w) + b\n",
    "        f_wb_i = sigmoid(z_i)\n",
    "        \n",
    "        err = f_wb_i - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err * x[i,j]\n",
    "        dj_db += (f_wb_i - y[i])\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    return dj_db, dj_dw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w (zeros):-0.1\n",
      "dj_dw at initial w (zeros):[-12.00921658929115, -11.262842205513591]\n"
     ]
    }
   ],
   "source": [
    "#checking fucntion\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "\n",
    "dj_db, dj_dw = compute_gradient(x_train, y_train, initial_w, initial_b)\n",
    "print(f'dj_db at initial w (zeros):{dj_db}' )\n",
    "print(f'dj_dw at initial w (zeros):{dj_dw.tolist()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "using above values in:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1}\\newline & \\rbrace\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, w, b, cost_function, gradient_values, alpha, num_iters, lambda_):\n",
    "    m = x.shape\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_values(x, y, w, b, lambda_)\n",
    "        \n",
    "        #now implement\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-40d2947e058b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m w,b, = gradient_descent(x_train ,y_train, initial_w, initial_b, \n\u001b[1;32m----> 9\u001b[1;33m                                    compute_cost, compute_gradient, alpha, iterations, 0)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-171c67df2ac8>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(x, y, w, b, cost_function, gradient_values, alpha, num_iters, lambda_)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mdj_dw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdj_db\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#now implement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-0702ccbf6357>\u001b[0m in \u001b[0;36mcompute_gradient\u001b[1;34m(x, y, w, b, lambda_)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_wb_i\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mdj_dw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdj_dw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mdj_db\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf_wb_i\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdj_dw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdj_dw\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "intial_w = 0.01 * (np.random.rand(2).reshape(-1,1) - 0.5)\n",
    "initial_b = -8\n",
    "\n",
    "iterations = 10000\n",
    "alpha = 0.001\n",
    "\n",
    "w,b, = gradient_descent(x_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
