{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "tf.autograph.set_verbosity(0)\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "    r = len(z)\n",
    "    a = []\n",
    "    for i in range(r):\n",
    "        q = np.exp(z[i]) / sum(np.exp(z))\n",
    "        a.append(q)    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_softmax:  [0.03205860328008499, 0.08714431874203257, 0.23688281808991013, 0.6439142598879722]\n",
      "tensorflow:  tf.Tensor([0.0320586  0.08714432 0.23688282 0.64391426], shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "z = np.array([1., 2.,3.,4.])\n",
    "#softmax from our function\n",
    "a = my_softmax(z)\n",
    "#tensorflow softmax\n",
    "atf = tf.nn.softmax(z)\n",
    "print('my_softmax: ',a)\n",
    "print('tensorflow: ',atf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    x_train = np.load('data/X.npy')\n",
    "    y_train = np.load('data/y.npy')\n",
    "    return x_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is:  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.56059680e-06\n",
      "  1.94035948e-06 -7.37438725e-04 -8.13403799e-03 -1.86104473e-02\n",
      " -1.87412865e-02 -1.87572508e-02 -1.90963542e-02 -1.64039011e-02\n",
      " -3.78191381e-03  3.30347316e-04  1.27655229e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.16421569e-04  1.20052179e-04\n",
      " -1.40444581e-02 -2.84542484e-02  8.03826593e-02  2.66540339e-01\n",
      "  2.73853746e-01  2.78729541e-01  2.74293607e-01  2.24676403e-01\n",
      "  2.77562977e-02 -7.06315478e-03  2.34715414e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.28335523e-17 -3.26286765e-04 -1.38651604e-02\n",
      "  8.15651552e-02  3.82800381e-01  8.57849775e-01  1.00109761e+00\n",
      "  9.69710638e-01  9.30928598e-01  1.00383757e+00  9.64157356e-01\n",
      "  4.49256553e-01 -5.60408259e-03 -3.78319036e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.10620915e-06\n",
      "  4.36410675e-04 -3.95509940e-03 -2.68537241e-02  1.00755014e-01\n",
      "  6.42031710e-01  1.03136838e+00  8.50968614e-01  5.43122379e-01\n",
      "  3.42599738e-01  2.68918777e-01  6.68374643e-01  1.01256958e+00\n",
      "  9.03795598e-01  1.04481574e-01 -1.66424973e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.59875260e-05\n",
      " -3.10606987e-03  7.52456076e-03  1.77539831e-01  7.92890120e-01\n",
      "  9.65626503e-01  4.63166079e-01  6.91720680e-02 -3.64100526e-03\n",
      " -4.12180405e-02 -5.01900656e-02  1.56102907e-01  9.01762651e-01\n",
      "  1.04748346e+00  1.51055252e-01 -2.16044665e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.87012352e-05 -6.40931373e-04\n",
      " -3.23305249e-02  2.78203465e-01  9.36720163e-01  1.04320956e+00\n",
      "  5.98003217e-01 -3.59409041e-03 -2.16751770e-02 -4.81021923e-03\n",
      "  6.16566793e-05 -1.23773318e-02  1.55477482e-01  9.14867477e-01\n",
      "  9.20401348e-01  1.09173902e-01 -1.71058007e-02  0.00000000e+00\n",
      "  0.00000000e+00  1.56250000e-04 -4.27724104e-04 -2.51466503e-02\n",
      "  1.30532561e-01  7.81664862e-01  1.02836583e+00  7.57137601e-01\n",
      "  2.84667194e-01  4.86865128e-03 -3.18688725e-03  0.00000000e+00\n",
      "  8.36492601e-04 -3.70751123e-02  4.52644165e-01  1.03180133e+00\n",
      "  5.39028101e-01 -2.43742611e-03 -4.80290033e-03  0.00000000e+00\n",
      "  0.00000000e+00 -7.03635621e-04 -1.27262443e-02  1.61706648e-01\n",
      "  7.79865383e-01  1.03676705e+00  8.04490400e-01  1.60586724e-01\n",
      " -1.38173339e-02  2.14879493e-03 -2.12622549e-04  2.04248366e-04\n",
      " -6.85907627e-03  4.31712963e-04  7.20680947e-01  8.48136063e-01\n",
      "  1.51383408e-01 -2.28404366e-02  1.98971950e-04  0.00000000e+00\n",
      "  0.00000000e+00 -9.40410539e-03  3.74520505e-02  6.94389110e-01\n",
      "  1.02844844e+00  1.01648066e+00  8.80488426e-01  3.92123945e-01\n",
      " -1.74122413e-02 -1.20098039e-04  5.55215142e-05 -2.23907271e-03\n",
      " -2.76068376e-02  3.68645493e-01  9.36411169e-01  4.59006723e-01\n",
      " -4.24701797e-02  1.17356610e-03  1.88929739e-05  0.00000000e+00\n",
      "  0.00000000e+00 -1.93511951e-02  1.29999794e-01  9.79821705e-01\n",
      "  9.41862388e-01  7.75147704e-01  8.73632241e-01  2.12778350e-01\n",
      " -1.72353349e-02  0.00000000e+00  1.09937426e-03 -2.61793751e-02\n",
      "  1.22872879e-01  8.30812662e-01  7.26501773e-01  5.24441863e-02\n",
      " -6.18971913e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.36563862e-03  3.68349741e-02  6.99079299e-01\n",
      "  1.00293583e+00  6.05704402e-01  3.27299224e-01 -3.22099249e-02\n",
      " -4.83053002e-02 -4.34069138e-02 -5.75151144e-02  9.55674190e-02\n",
      "  7.26512627e-01  6.95366966e-01  1.47114481e-01 -1.20048679e-02\n",
      " -3.02798203e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.76572712e-04 -6.51415556e-03  1.17339359e-01\n",
      "  4.21948410e-01  9.93210937e-01  8.82013974e-01  7.45758734e-01\n",
      "  7.23874268e-01  7.23341725e-01  7.20020340e-01  8.45324959e-01\n",
      "  8.31859739e-01  6.88831870e-02 -2.77765012e-02  3.59136710e-04\n",
      "  7.14869281e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.53186275e-04  3.17353553e-04 -2.29167177e-02\n",
      " -4.14402914e-03  3.87038450e-01  5.04583435e-01  7.74885876e-01\n",
      "  9.90037446e-01  1.00769478e+00  1.00851440e+00  7.37905042e-01\n",
      "  2.15455291e-01 -2.69624864e-02  1.32506127e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36366422e-04\n",
      " -2.26031454e-03 -2.51994485e-02 -3.73889910e-02  6.62121228e-02\n",
      "  2.91134498e-01  3.23055726e-01  3.06260315e-01  8.76070942e-02\n",
      " -2.50581917e-02  2.37438725e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  6.20939216e-18  6.72618320e-04 -1.13151411e-02\n",
      " -3.54641066e-02 -3.88214912e-02 -3.71077412e-02 -1.33524928e-02\n",
      "  9.90964718e-04  4.89176960e-05  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print ('The first element of X is: ', x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of y is:  0\n",
      "The last element of y is:  9\n"
     ]
    }
   ],
   "source": [
    "print ('The first element of y is: ', y_train[0,0])\n",
    "print ('The last element of y is: ', y_train[-1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (5000, 400)\n",
      "The shape of y is: (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X is: ' + str(x_train.shape))\n",
    "print ('The shape of y is: ' + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06660b924dc466c9cbf94a6512bb56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "m, n = x_train.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(5,5))\n",
    "fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.91]) #[left, bottom, right, top]\n",
    "\n",
    "#fig.tight_layout(pad=0.5)\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random_reshaped = x_train[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(y_train[random_index,0])\n",
    "    ax.set_axis_off()\n",
    "    fig.suptitle(\"Label, image\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters have dimensions that are sized for a neural network with  25  units in layer 1,  15  units in layer 2 and  10  output units in layer 3, one for each digit.\n",
    "\n",
    "Recall that the dimensions of these parameters is determined as follows:\n",
    "\n",
    "If network has  𝑠𝑖𝑛  units in a layer and  𝑠𝑜𝑢𝑡  units in the next layer, then\n",
    "𝑊  will be of dimension  𝑠𝑖𝑛×𝑠𝑜𝑢𝑡 .\n",
    "𝑏  will be a vector with  𝑠𝑜𝑢𝑡  elements\n",
    "Therefore, the shapes of W, and b, are\n",
    "\n",
    "layer1: The shape of W1 is (400, 25) and the shape of b1 is (25,)\n",
    "\n",
    "layer2: The shape of W2 is (25, 15) and the shape of b2 is: (15,)\n",
    "\n",
    "layer3: The shape of W3 is (15, 10) and the shape of b3 is: (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234) # for consistent results\n",
    "model = Sequential([\n",
    "    #input layer\n",
    "    tf.keras.Input(shape=(400,)),\n",
    "    #hidden layers\n",
    "    Dense(25,activation = 'relu', name = 'L1'),\n",
    "    Dense(15, activation = 'relu', name = 'L2'),\n",
    "    #output layer\n",
    "    Dense(10, activation = 'linear', name = 'L3')\n",
    "], name = 'my_model')\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 25)                10025     \n",
      "                                                                 \n",
      " L2 (Dense)                  (None, 15)                390       \n",
      "                                                                 \n",
      " L3 (Dense)                  (None, 10)                160       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,575\n",
      "Trainable params: 10,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape = (400, 25), b1 shape = (25,)\n",
      "W2 shape = (25, 15), b2 shape = (15,)\n",
      "W3 shape = (15, 10), b3 shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.0306\n",
      "Epoch 2/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0281\n",
      "Epoch 3/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0250\n",
      "Epoch 4/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0226\n",
      "Epoch 5/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 6/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 7/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 8/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 9/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0222\n",
      "Epoch 10/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 11/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0125\n",
      "Epoch 12/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0118\n",
      "Epoch 13/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0121\n",
      "Epoch 14/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0105\n",
      "Epoch 15/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 16/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0112\n",
      "Epoch 17/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 18/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 19/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0071\n",
      "Epoch 20/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0062\n",
      "Epoch 21/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 22/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0059\n",
      "Epoch 23/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0057\n",
      "Epoch 24/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 25/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0046\n",
      "Epoch 26/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0039\n",
      "Epoch 27/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0034\n",
      "Epoch 28/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "Epoch 29/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0029\n",
      "Epoch 30/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "Epoch 31/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "Epoch 32/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0024\n",
      "Epoch 33/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0022\n",
      "Epoch 34/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 35/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0290\n",
      "Epoch 36/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0088\n",
      "Epoch 37/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "Epoch 38/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0021\n",
      "Epoch 39/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0017\n",
      "Epoch 40/40\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0016\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,y_train,\n",
    "    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\" display a single digit. The input is one digit (400,). \"\"\"\n",
    "def display_a_digit(X):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(0.5,0.5))\n",
    "    fig.canvas.toolbar_visible = False\n",
    "    fig.canvas.header_visible = False\n",
    "    fig.canvas.footer_visible = False   \n",
    "    X_reshaped = X.reshape((20,20)).T\n",
    "    # Display the image\n",
    "    ax.imshow(X_reshaped, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef3de599b3a49c698cfab7cccb34294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicting a Two: \n",
      "[[-12.922445   -3.9776735   2.7201824  -3.5822005 -22.05717   -15.555857\n",
      "  -19.23509    -8.497258  -10.322394  -12.857491 ]]\n",
      " Largest Prediction index: 2\n"
     ]
    }
   ],
   "source": [
    "image_of_two = x_train[1015]\n",
    "display_a_digit(image_of_two)\n",
    "\n",
    "prediction = model.predict(image_of_two.reshape(1,400))  # prediction\n",
    "\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
